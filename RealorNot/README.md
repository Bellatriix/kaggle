# 推特内容真实性预测

本项目为Kaggle中，”Real or Not? NLP with Disaster Tweets“。<br/>
此处使用了三种方法：基本的神经网络模型，改进的神经网络模型，和BERT模型。<br/>
<br/>
基本的神经网络模型：LSTM和一个全连接层。<br/>
改进的神经网络模型：在基础的模型之上，加入卷积层、池化层和双向LSTM传播层。<br/>
BERT模型：使用tensorflow_hub上的BERT模型进行建模，最后加入全连接层进行分类。<br/>
<br/>
数据集可在官网下载。建模时，使用tensorboard作为回调，生成log文件，可通过tensorboard查看每种模型的训练过程。<br/>
<br/>
# 结果

基本模型效果较差，训练时间较长，每次迭代大约90秒。<br/>
改进后的模型效果相对较好，训练时间有极大提升，每次不到20秒<br/>
BERT模型虽然每次迭代大约需要5分钟，但效果最好。<br/>
注：BERT模型不需要进行数据预处理，直接将原始数据导入模型即可。前两种模型均需要预处理，且预处理时间根据文本信息内容的多少呈正相关。
